########################################################################################################
                                   #YAML CONFIGURATION FILE:

#This file lists all the hyperparameters, parameters, and paths necessary for the proper functioning 
#of the network. These will be divided into sections for better readability.
########################################################################################################

                                #################################
                                #        DATASET PATH
                                #################################
dataroot: #Dataset path
    "C:/Users/andre/OneDrive/Desktop/MAGISTRALE/AI_Project/Dataset/AirQualityUCI.csv"
results_path: #Results directory path
    'D:/Results'             
               
            ###########################################################################

            #                       FILE:   autoencoder.py

            ###########################################################################

                                #################################
                                #            PATHS:
                                #################################
reduce_dataset_autoencoder_path: #Path to the new clean and reduced dataset
    "C:/Users/andre/OneDrive/Desktop/MAGISTRALE/AI_Project/Dataset/dataset_reduced_Autoencoder.csv"
path_pth_autoencoder: #Path of the autoencoder model
    "D:/Results/Autoencoder/autoencoder_lastEpoch.pth"
path_txt_autoencoder: #Path of the autoencoder text file
    "D:/Results/Autoencoder/autoencoder_lastEpoch.txt"
image_loss_path: #Path of the loss trend image
    "D:/Results/Autoencoder/loss_plot.png"        

                                #################################
                                #       HYPERPARAMETERS:
                                #################################
n_epochs: #Epochs
    600
lr: #Learning rate
    0.01
batch_size: #Mini-batch dimension
    128
loss_function: #Mean Square Error("mse") or Mean Absolute Error("mae")
    "mse"
optimizer: #Adam("adam") or Stochastic Gradient Descent("sgd") or Root Mean Square Propagation("rmsprop")
    "adam"
                     
            ############################################################################

            #                          FILE:   main.py

            ############################################################################

                                #################################
                                #            PATHS:
                                #################################
reduce_dataset_path: #Path to the new clean and reduced dataset
    "C:/Users/andre/OneDrive/Desktop/MAGISTRALE/AI_Project/Dataset/dataset_reduced.csv"
path_pth_net: #Path of the net model
    "D:/Results/NET/net_lastEpoch.pth"
path_txt_net: #Path of the net text file
    "D:/Results/NET/net_lastEpoch.txt"
result_path_net: #Path of the loss trend image
    "D:/Results/NET/loss_plot.png" 
split_path:
    "C:/Users/andre/OneDrive/Desktop/MAGISTRALE/AI_Project/Dataset"
                                
                                #################################
                                #       HYPERPARAMETERS:
                                #################################
epochs_net: #Epochs
    8000
learning_rate_net: #Learning rate
    0.05
mini_batch_size_net: #Mini-batch dimension
    256
loss_function_net: #Mean Square Error("mse") or Mean Absolute Error("mae")
    "mse"
optimizer_net: #Adam("adam") or Stochastic Gradient Descent("sgd") or Root Mean Square Propagation("rmsprop")
    "sgd"

                                #################################
                                #              MLP
                                #################################
input_size_mlp: #Dimension of the input layer
    1
output_size_mlp: #Dimension of the output layer
    1
hidden_layers_mlp: #Dimensions list of the hidden layer (the dimensions go from the first element of the list, which corresponds to the first hidden layer, to the last, which corresponds to the last hidden layer)
    [10]


                                #################################
                                #             GMM:
                                #################################

num_gaussians: #Number of Gaussians we want to use in the GMM sample generator
    32
n_samples: #Number of samples which we want generate
    6944